{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhIqm9nobeij"
      },
      "source": [
        "# Машинный перевод и озвучивание видеозаписей на русском языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## О проекте"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Есть](https://www.youtube.com/watch?v=p3lsYlod5OU&ab_channel=LexFridman) интересная беседа [Лекса Фридмана](https://en.wikipedia.org/wiki/Lex_Fridman) с [Михаилом Левиным](https://en.wikipedia.org/wiki/Michael_Levin_(biologist)). Несмотря, на русское происхождение обоих собеседников разговор они ведут на английском. Цель проекта перевести и озвучить беседу на русском языке.\n",
        "\n",
        "В проекте используется [готовая расшифровка с таймингом](https://karpathy.ai/lexicap/0325-large.html), созданная с помощью пакета [OpenAI Wisper](https://github.com/openai/whisper).\n",
        "Далее описывается парсинг расшифровки, перевод на русский язык, машинное озвучивание, выравнивание длины русских фрагментов с соответствующими оригинальными.\n",
        "\n",
        "Данный подход можно использовать для перевода и озвучивания любой видеозаписи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwHHuGEObeio"
      },
      "source": [
        "## Устанавливаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlYFsjZJjzR7",
        "outputId": "17e6e958-c734-4093-9d69-f327a92b7e6e"
      },
      "outputs": [],
      "source": [
        "# %pip install tqdm\n",
        "# %pip install python-docx\n",
        "# %pip install -q torchaudio omegaconf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWDfesh2beiv"
      },
      "source": [
        "## Импортируем необходимые для работы модули"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_PNSa_KjzR_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from scipy.io.wavfile import read, write\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from omegaconf import OmegaConf\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
        "                               'latest_silero_models.yml',\n",
        "                               progress=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-9FvG0jbei1"
      },
      "source": [
        "## Парсинг расшифровки с таймингом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для парсинга используем библиотеку `BeatifulSoup`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM1zeSyUjzSD"
      },
      "outputs": [],
      "source": [
        "url = 'https://karpathy.ai/lexicap/0325-large.html'\n",
        "data = requests.get(url).text\n",
        "soup = BeautifulSoup(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTjxnSFebei3"
      },
      "source": [
        "## Обработка английского текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выделим фрагменты текста и их тайминги в отдельные списки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90FAjblN_YGR"
      },
      "outputs": [],
      "source": [
        "t_divs = soup.find_all('div', {'class': 't'})\n",
        "en_text = []\n",
        "for div in t_divs:\n",
        "    en_text.append(div.text)\n",
        "\n",
        "s_divs = soup.find_all('div', {'class': 's'})\n",
        "timing = []\n",
        "for div in s_divs:\n",
        "    timing.append(div.a.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Важно в процессе работы над текстом не потерять ни одного символа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_size = 0\n",
        "for row in en_text:\n",
        "    text_size += len(row)\n",
        "\n",
        "text_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Почти две сотни знаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для удовлетворительного качества необходимо переводить текст как минимум целыми предложениями. В качестве знаков для разделения используем точку и вопросительный знак."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnDKkBZY_4SI"
      },
      "outputs": [],
      "source": [
        "def sign_finder(sign, str):\n",
        "    '''Finds the last position of the sing in the string'''\n",
        "    rev_pos = str[::-1].find(sign)\n",
        "    if rev_pos == -1:\n",
        "        return 0    \n",
        "    pos = len(str) - rev_pos\n",
        "    return pos\n",
        "def pos_finder(text):\n",
        "    signs = ['.', '?']\n",
        "    pos = []\n",
        "    for sign in signs:\n",
        "        pos.append(sign_finder(sign, text))\n",
        "    return max(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Перенесём незаконченные фрагменты предложений к фрагментам, содержащим знаки конца предложения, и внесём соответствующие поправки в тайминг."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfrthd1t_dWf"
      },
      "outputs": [],
      "source": [
        "dense_text = []\n",
        "new_timing = []\n",
        "buffer = []\n",
        "time = []\n",
        "for i, text in enumerate(en_text):\n",
        "    pos = pos_finder(text)\n",
        "    if (pos == 0) & (i < len(en_text) - 1):\n",
        "        buffer.append(text)\n",
        "        time.append(timing[i])\n",
        "    elif len(buffer) > 0:\n",
        "        merged = \"\"\n",
        "        for buf_item in buffer:\n",
        "            merged += buf_item \n",
        "        dense_text.append(merged + text)\n",
        "        new_timing.append(time[0])\n",
        "        buffer.clear()\n",
        "        time.clear()\n",
        "    else:\n",
        "        dense_text.append(text)\n",
        "        new_timing.append(timing[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dense_size = 0\n",
        "for row in dense_text:\n",
        "    dense_size += len(row)\n",
        "dense_size == text_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Пока всё на месте."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Из данных списков создадим таблицу `Pandas`: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QLp2OY5jzSH"
      },
      "outputs": [],
      "source": [
        "dict = {'timing': new_timing, 'en_text': dense_text}\n",
        "df = pd.DataFrame(dict)\n",
        "print(df.en_text.iloc[40])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Тайминги переведем в формат `DateFrame` и вычислим продожительность оригинальных фрагментов, сохранив их в отдельный столбец:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt0udXiGbei5"
      },
      "outputs": [],
      "source": [
        "format = '%H:%M:%S.%f'\n",
        "def duration_calculator(row):\n",
        "    '''Calculates duration speech fragment in a row'''\n",
        "    idx = row.name\n",
        "    time1 = row['timing'] + '000'\n",
        "    if idx == len(df) - 1:\n",
        "        return datetime.strptime(\"03:00:20.000000\", format) - datetime.strptime(time1, format)    \n",
        "    time2 = df.loc[idx + 1, 'timing'] + '000'\n",
        "    return datetime.strptime(time2, format) - datetime.strptime(time1, format)\n",
        "\n",
        "df['duration'] = df.apply(duration_calculator, axis=1)\n",
        "df['duration'] = df['duration'].apply(lambda x: x.total_seconds())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на длину фрагментов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIwNRDx4FagG",
        "outputId": "e31c6a8a-68b5-41b4-c915-52601cd82cdb"
      },
      "outputs": [],
      "source": [
        "df.en_text.apply(len).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Самый короткий 5 символов, а длинный -- 574. \n",
        "\n",
        "Для перевода фрагментов текста в отдельные предложения (группы предложений) и определения соответствующей им временной продолжительности мне будет удобнее работать со списками, а не таблицей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FkIVmdc-W5c"
      },
      "outputs": [],
      "source": [
        "text = list(df.en_text)\n",
        "duration = list(df.duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Будем ориентироваться на знаки окончания предложения в конце фрагмента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxT0KDyK_twL"
      },
      "outputs": [],
      "source": [
        "def min_pos_finder(text):\n",
        "    '''Returns the first position of the signs in the text'''\n",
        "    signs = ['.', '?']\n",
        "    pos = []\n",
        "    for sign in signs:\n",
        "        pos.append(text.find(sign))\n",
        "    if min(pos) == -1:\n",
        "        return max(pos) + 1\n",
        "    else:\n",
        "        return min(pos) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Собственно переносим, что нужно в тексте и вносим, соответствующие изменения в их длительность:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmUI4oSb-i5m"
      },
      "outputs": [],
      "source": [
        "for i, row in enumerate (text):\n",
        "    if i != 0:\n",
        "        pos = min_pos_finder(row)\n",
        "        head = row[:pos]\n",
        "        tail = row[pos:]\n",
        "        duration[i - 1] = duration[i - 1] + duration[i] * len(head) / len(row)\n",
        "        duration[i] = duration[i] * len(tail) / len(row)\n",
        "        text[i - 1] = text[i - 1] + head\n",
        "        text[i] = tail         \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3FdfaQTG_d5",
        "outputId": "0164cbff-4cec-4b48-e1b4-1e128ff47881"
      },
      "outputs": [],
      "source": [
        "size = 0\n",
        "for row in text:\n",
        "    size += len(row)\n",
        "\n",
        "print('Количество знаков в исходном тексте: ', df.en_text.apply(len).sum())\n",
        "print('Количество знаков итоговом тексте: ', size)\n",
        "print('Исходная общая продолжительность: ', sum(duration))\n",
        "print('Общая продолжительность после обработки: ', df.duration.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Всё на месте. Возвращаем данные обратно в таблицу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['en_text'] = text\n",
        "df['duration'] = duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LoLeH3XbejD"
      },
      "source": [
        "## Перевод текста на русский"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для перевода будем использовать десктопный вариант переводчика DeepL. Из-за ограничения в 100 000 символов нам потребуется несколько текстовых документов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lists = []\n",
        "for i in range(len(text)):\n",
        "    lists.append([text[i], duration[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 500\n",
        "start = 0\n",
        "for i in range(round(len(text) / batch_size)):\n",
        "    document = Document()\n",
        "    table = document.add_table(rows=0, cols=3)\n",
        "\n",
        "    batch = lists[start:start+batch_size]\n",
        "\n",
        "    for j, row in enumerate(batch):\n",
        "        row_cells = table.add_row().cells\n",
        "        row_cells[0].text = f'{j}'\n",
        "        row_cells[1].text = row[0]\n",
        "        row_cells[2].text = f'{row[1]:.4f}'\n",
        "\n",
        "    start += batch_size\n",
        "    document.save(f'tab_{i + 1}.docx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ru_text = []\n",
        "for i in range(round(len(text) / batch_size)):\n",
        "    document = Document(f'tab_{i + 1} ru.docx')\n",
        "    table = document.tables[0]\n",
        "    for cell in table.column_cells(1):\n",
        "        ru_text.append(cell.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document = Document()\n",
        "for txt in ru_text:\n",
        "    document.add_paragraph(txt)\n",
        "document.save('ru_text.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ru_text = []\n",
        "document = Document('ru_text.docx')\n",
        "for p in document.paragraphs:\n",
        "    ru_text.append(p.text[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(ru_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjB8_8ctbejJ"
      },
      "source": [
        "## Машинное озвучивание текста и подготовка к монтажу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В качестве синтеза речи будем использовать замечательные модели от [Silero](https://colab.research.google.com/github/snakers4/silero-models/blob/master/examples_tts.ipynb#scrollTo=_-S9KQ19mzpy), которые доступны всем желающим для некомерческого использования:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = OmegaConf.load('latest_silero_models.yml')\n",
        "language = 'ru'\n",
        "model_id = 'v3_1_ru'\n",
        "device = torch.device('cpu')\n",
        "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                     model='silero_tts',\n",
        "                                     language=language,\n",
        "                                     speaker=model_id)\n",
        "model.to(device)  # gpu or cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Пустых элементов быть не должно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ru_text[377] = 'Это определенно стимулирует взгляд на себя и внешний мир как на объект, я думаю, это неизбежно.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_wave(path, audio, sample_rate):\n",
        "    \"\"\"Writes a .wav file.\n",
        "    Takes path, PCM audio data, and sample rate.\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "        wf.setnchannels(1)\n",
        "        wf.setsampwidth(2)\n",
        "        wf.setframerate(sample_rate)\n",
        "        wf.writeframes(audio)\n",
        "for i, txt in tqdm(enumerate(ru_text)):\n",
        "  txt = f'<speak><prosody rate=\"fast\">{txt}</prosody></speak>'\n",
        "  sample_rate = 48000\n",
        "  speaker = 'xenia'\n",
        "  audio = model.apply_tts(ssml_text=txt,\n",
        "                        speaker=speaker,\n",
        "                        sample_rate=sample_rate)\n",
        "  write_wave(path=f'files/{i}-1.wav', audio=(audio * 32767).numpy().astype('int16'), sample_rate=48000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdS9OZoKYt87"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame({'duration': duration, 'en_text': text, 'ru_text': ru_text})\n",
        "# df.to_csv('levin.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLDIZsm4acmk"
      },
      "source": [
        "Теперь, даже после перерыва, мы можем загрузить таблицу из файла:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "J5lYS1pcjzSV",
        "outputId": "6e02058f-118b-4c26-bccc-3e2c756ad344"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('levin.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RNnXis6bejN"
      },
      "source": [
        "Создадим набор звуковых файлов из текстовых фрагментов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpqUjdmQbejO"
      },
      "source": [
        "## Обработка звука"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lO1hQwebejO"
      },
      "source": [
        "Сравним длину полученных фрагментов с длительностью оригинальных фрагментов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuVcQjoybejO"
      },
      "outputs": [],
      "source": [
        "durs = []\n",
        "for i in range(len(df)):\n",
        "    file_name = 'files/' + f'{i}-1.wav'\n",
        "    fs, data = read(file_name)\n",
        "    durs.append(round(len(data) / fs, 3))   \n",
        "sum(durs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Общая длительность озвучивания 9555 секунд,  меньше общей длительности видеозаписи -- 10820 секунд."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk-CgS0YbejP"
      },
      "source": [
        "Найдём разность между оригинальной длительностью фрагмента и русской озвучкой:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plq3c7PPbejQ"
      },
      "outputs": [],
      "source": [
        "df['ru_duration'] = durs\n",
        "df['delta_duration'] = df['duration'] - df['ru_duration']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.delta_duration.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Оригинальный фрагмент может быть на 14 секунд длиннее, а может и почти на 6 секунд короче."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.delta_duration.sum() + df.ru_duration.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Общая продолжительность совпадает с оригинальной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Если длительности озвученных фрагментов превышает оригинал, то заберём это время у следующих фрагментов, обладающих запасом по времени. Работать будем со списком. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deltas = list(df.delta_duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time = 0\n",
        "for i, delta in enumerate(deltas):\n",
        "    \n",
        "    if delta < 0:        \n",
        "        time += delta\n",
        "        deltas[i] = 0\n",
        "    elif time < 0:\n",
        "        if abs(time) <= delta:\n",
        "            deltas[i] += time\n",
        "            time = 0\n",
        "        else:\n",
        "            time += delta \n",
        "            deltas[i] = 0       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.duration.sum())\n",
        "print(df.ru_duration.sum() + df.delta_duration.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Общее время не поменялось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Добавим информацию в таблицу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['delta_duration'] = deltas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fs = 48000\n",
        "for i, delta in enumerate(deltas):\n",
        "  if delta > 0:\n",
        "    multiplicator = int(delta * fs)\n",
        "    spacer = np.array([0] * multiplicator).astype('int16')\n",
        "    write_wave(\n",
        "      path=f'{i}.wav',\n",
        "      audio=spacer,\n",
        "      sample_rate=fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_durs = []\n",
        "for i, delta in enumerate(deltas):\n",
        "  if delta > 0:\n",
        "    file_name = f'files/{i}-1.wav'\n",
        "    fs, data = read(file_name)\n",
        "    d_durs.append(round(len(data) / fs, 3))   \n",
        "sum(d_durs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.delta_duration.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUSgEvU3bejS"
      },
      "source": [
        "Добавим после каждого вновь озвученного звукового фрагмента, продолжительностью меньше оригинального, заполненной тишиной спейсер, необходимой продолжительности:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Можно попробовать \"сшить\" фрагменты русской озвучки со спейсерами с помощью утилиты [`ffmpeg`](https://ffmpeg.org/download.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ru_text[377]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"list.txt\", \"w\") as f:\n",
        "    for i in range(len(df)):\n",
        "        filename = f'files/{i}.wav'\n",
        "        line = f\"file '{filename}'\\n\"\n",
        "        if deltas[i] > 0:\n",
        "            line += f\"file 'files/{i}-1.wav'\\n\"\n",
        "        f.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system(\"ffmpeg -f concat -i out/list.txt -c copy out/output.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По неизвестной мне причине, итоговый файл у меня получился размером больше, чем должен был. Я использовал для объединения утилиту плеера `AIMP`, указав папку `files` как источник и один файл с раширением `.mp3`. Последний вариант хорошо сработал и я получил на выходе звуковой файл продолжительностью 3 часа 20 секунд (10820 секунд)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Далее я загружаю оригинальный файл с видео на ПК с помощью сервиса [SaveFrom](https://ru.savefrom.net/1-%D0%B1%D1%8B%D1%81%D1%82%D1%80%D1%8B%D0%B9-%D1%81%D0%BF%D0%BE%D1%81%D0%BE%D0%B1-%D1%81%D0%BA%D0%B0%D1%87%D0%B0%D1%82%D1%8C-%D1%81-youtube-130/?url=http%3A%2F%2Fyoutube.com%2Fwatch%3Fv%3Dp3lsYlod5OU&ab_channel=LexFridman&utm_source=youtube.com&utm_medium=short_domains&utm_campaign=ssyoutube.com&a_ts=1666604287.019) и в видеоредакторе приглушаю оригинальную видеодорожку и добавляю вновь созданную. Можно попробовать обойтись средствами утилиты `ffmpeg`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Общий вывод\n",
        "\n",
        "Результат можно посмотреть [здесь](https://youtu.be/7HZnJYKBXNo)\n",
        "\n",
        "На мой взгляд результат получился значительно лучше чем в предыдущей итерации. Качество перевода улучшилось, хотя и далеко не идеальное, в этом направлении следует продолжить работать. Качество озучивание значительно улучшилось, однако остались проблемы с ударениями, буквы ё пришлось выделять самостоятельно.\n",
        "\n",
        "Крайне желательно использовать надежный нормализатор текста. Входящий в состав моделей Silero (если он там вообще есть) работает неудовлетворильно, мне пришлось делать много работы самостоятельно.\n",
        "Можно попробовать реализовать на основе данного проекта суфлёр и озвучить текст перевода самостоятельно."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
